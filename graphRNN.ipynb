{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRNNAutomaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from exporter import read_automatas\n",
    "from wandb_utilities import get_wandb_sweep_name, create_sweep\n",
    "from automatonRNN import AutomatonRNN, generate_automatas\n",
    "from property_validator import validate_property, get_metrics\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "ENTITY = 'verification_thesis'\n",
    "PROJECT = 'AutomatonRNN'\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If some of the parameters are changed, the sweep must be recreated\n",
    "automata_property = 'unique_accepting'\n",
    "number_of_states = 5\n",
    "alphabet_len = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'./dataset/{number_of_states}_states/{automata_property}_property_automatas'\n",
    "automatas = read_automatas(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_graphs(dataset, batch_size):\n",
    "    dataset1, dataset2 = dataset\n",
    "\n",
    "    shuffled_ds1, shuffled_ds2 = shuffle(dataset1, dataset2, random_state=0)\n",
    "\n",
    "    batches1 = [shuffled_ds1[i:min(len(dataset1), i+batch_size)] for i in range(0, len(dataset1), batch_size)]\n",
    "    batches2 = [shuffled_ds2[i:min(len(dataset2), i+batch_size)] for i in range(0, len(dataset2), batch_size)]\n",
    "    return batches1, batches2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining data from a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_symbol = 0\n",
    "def add_padding_to_transitions(graphs):\n",
    "    max_len = max([len(g) for g in graphs])\n",
    "    new_graphs = []\n",
    "    for graph in graphs:\n",
    "        \n",
    "        len_diff = max_len-len(graph)\n",
    "\n",
    "        new_graph = []\n",
    "        padding = np.full(len_diff, padding_symbol)\n",
    "        for row in graph:\n",
    "            new_graph.append(np.concatenate((row, padding)))   \n",
    "\n",
    "        for _ in range(len_diff):\n",
    "            new_graph.append(np.full(max_len, padding_symbol))\n",
    "\n",
    "        new_graphs.append(new_graph)\n",
    "\n",
    "    return np.array(new_graphs)\n",
    "\n",
    "def add_padding_to_final_states(all_final_states):\n",
    "    max_len = max([len(fs) for fs in all_final_states])\n",
    "    padded_final_states = []\n",
    "    for final_states in all_final_states:\n",
    "        len_diff = max_len-len(final_states)\n",
    "        padding = np.full(len_diff, padding_symbol)\n",
    "        padded_final_states.append(np.concatenate((final_states, padding)))\n",
    "    return np.array(padded_final_states)\n",
    "\n",
    "def add_padding_to_graph(transitions, final_states):\n",
    "    return add_padding_to_transitions(transitions), add_padding_to_final_states(final_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_conns(graphs, node, m):\n",
    "    batch_size = graphs.shape[0]\n",
    "\n",
    "    initial_pos = max(0, node - m)\n",
    "    in_conns = np.array(graphs[:,initial_pos:node,node], dtype=np.float32)\n",
    "    loop_con = np.array(np.expand_dims(graphs[:,node,node],1), dtype=np.float32)\n",
    "    out_conns = np.array(graphs[:,node,initial_pos:node], dtype=np.float32)\n",
    "    \n",
    "    padding_size = max(0, m - node)\n",
    "    padding = np.zeros((batch_size,padding_size),dtype=np.float32)\n",
    "    y_conns = np.concatenate((padding, in_conns, loop_con, out_conns, padding), 1)\n",
    "    return torch.tensor(y_conns, dtype=torch.float32)\n",
    "\n",
    "def get_target_is_final(final_nodes, node):\n",
    "    return torch.tensor(final_nodes[:,node], dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "def get_target_is_end(nodes, node):\n",
    "    # we sum 0 to transform bools to int\n",
    "    return torch.tensor((nodes == node) + 0, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "def get_nodes(graphs):\n",
    "    return np.array([len(g) for g in graphs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_loss(y_hat, y):\n",
    "    conns_hat, final_prob_hat, end_prob_hat = y_hat\n",
    "    conns, final_prob, end_prob = y\n",
    "    # Convert to batch and BCE loss for conns\n",
    "    conns_loss = nn.BCELoss()(conns_hat, conns)\n",
    "    # BCE loss for final prob\n",
    "    final_prob_loss = nn.BCELoss()(final_prob_hat, final_prob)\n",
    "    # BCE loss for end prob\n",
    "    end_prob_loss = nn.BCELoss()(end_prob_hat, end_prob)\n",
    "\n",
    "    # Total loss us the sum of all losses\n",
    "    return conns_loss + final_prob_loss + end_prob_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, dataset, criterion, epochs, batch_size, gradient_clip):\n",
    "    dataset_len = len(dataset[0])\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        start_time = time.time()\n",
    "        loss_val, iters = 0, 0\n",
    "        all_transitions, all_final_states = get_batch_graphs(dataset, batch_size)\n",
    "        for i, transitions in enumerate(all_transitions):\n",
    "            final_states = all_final_states[i]\n",
    "            bs = len(final_states)\n",
    "\n",
    "            iter_loss = 0\n",
    "            x = model.get_sos(bs)\n",
    "            h = model.get_initial_hidden(bs)\n",
    "\n",
    "            nodes = get_nodes(transitions)\n",
    "            max_node = max(nodes)\n",
    "\n",
    "            padded_transitions, padded_final_states = add_padding_to_graph(transitions, final_states)\n",
    "            \n",
    "            for node in range(max_node):\n",
    "                optim.zero_grad()\n",
    "\n",
    "                # Get targets \n",
    "                y_conns = get_target_conns(padded_transitions, node, model.m)\n",
    "                y_final = get_target_is_final(padded_final_states, node)\n",
    "                y_end = get_target_is_end(nodes, node)\n",
    "                y = torch.cat((y_conns, y_final, y_end), 1)\n",
    "\n",
    "                # Run one iteration of the model\n",
    "                pred, hidden = model(x, h)\n",
    "                \n",
    "                # Compute the loss function\n",
    "                loss = criterion(pred, y)\n",
    "                loss.backward(retain_graph=True)\n",
    "\n",
    "                if gradient_clip == 'norm':\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "                if gradient_clip == 'clip':\n",
    "                    torch.nn.utils.clip_grad_value_(model.parameters(), .5)\n",
    "                optim.step()\n",
    "\n",
    "                # Update hidden and x values for next iteration\n",
    "                h = hidden.reshape(1,bs,-1).detach().requires_grad_()\n",
    "                x = pred.reshape(bs,1,-1).detach().requires_grad_()\n",
    "\n",
    "                # Acumulate loss value\n",
    "                iter_loss += loss.item()\n",
    "                iters += 1\n",
    "\n",
    "            loss_val += iter_loss / iters\n",
    "        if epoch%1==5:\n",
    "            print(f\"Epoch {epoch}, duration: {time.time()-start_time}s -- TRAIN: loss {loss_val/dataset_len}\")\n",
    "        wandb.log({'train_loss': loss_val/dataset_len})\n",
    "                \n",
    "    return model, loss_val/dataset_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    with wandb.init():\n",
    "        config = wandb.config\n",
    "        \n",
    "        m = config.sliding_window_size\n",
    "        hidden_dim = config.hidden_dim\n",
    "        automaton_rnn = AutomatonRNN(m, hidden_dim)\n",
    "\n",
    "        #if config.loss == 'separated':\n",
    "        #    pass\n",
    "        \n",
    "        criterion = nn.BCELoss(weight=torch.Tensor(np.ones(2*m+3)*100))\n",
    "\n",
    "        optim = torch.optim.Adam(automaton_rnn.parameters(), lr=.002)\n",
    "\n",
    "        automaton_rnn, final_loss = train_model(automaton_rnn, optim, automatas, criterion, epochs=config.epochs, batch_size=config.batch_size)\n",
    "\n",
    "        number_to_generate = 1000\n",
    "        bs_to_generate = 20\n",
    "        generated_automatons = []\n",
    "        for _ in range(0, number_to_generate, bs_to_generate):\n",
    "            generated_automatons = generated_automatons + generate_automatas(automaton_rnn, 20, bs_to_generate, alphabet_len)\n",
    "\n",
    "        results = get_metrics(automata_property, generated_automatons)\n",
    "\n",
    "        print(f'Finished training!!! Final loss: {final_loss} --- Final results: {results}')\n",
    "\n",
    "        wandb.log(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 21dq5twn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsliding_window_size: 3\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjuancommits\u001b[0m (\u001b[33mverification_thesis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\Juan\\Ort\\Master\\IAGenerativa\\GraphRNNAutomaton\\wandb\\run-20231124_165142-21dq5twn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/verification_thesis/AutomatonRNN/runs/21dq5twn' target=\"_blank\">faithful-sweep-2</a></strong> to <a href='https://wandb.ai/verification_thesis/AutomatonRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/verification_thesis/AutomatonRNN' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/verification_thesis/AutomatonRNN/runs/21dq5twn' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/runs/21dq5twn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [33:54<00:00, 33.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!!! Final loss: 0.022237485705759154 --- Final results: {'mean_accepting_states': 0.888, 'accuracy': 31.4}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>mean_accepting_states</td><td>▁</td></tr><tr><td>train_loss</td><td>█▁▁▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>31.4</td></tr><tr><td>mean_accepting_states</td><td>0.888</td></tr><tr><td>train_loss</td><td>0.02224</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-sweep-2</strong> at: <a href='https://wandb.ai/verification_thesis/AutomatonRNN/runs/21dq5twn' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/runs/21dq5twn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231124_165142-21dq5twn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2u6em0z5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsliding_window_size: 3\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\Juan\\Ort\\Master\\IAGenerativa\\GraphRNNAutomaton\\wandb\\run-20231124_172554-2u6em0z5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/verification_thesis/AutomatonRNN/runs/2u6em0z5' target=\"_blank\">swept-sweep-3</a></strong> to <a href='https://wandb.ai/verification_thesis/AutomatonRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/verification_thesis/AutomatonRNN' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/verification_thesis/AutomatonRNN/runs/2u6em0z5' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/runs/2u6em0z5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:36<00:00, 11.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!!! Final loss: 0.024263193179961492 --- Final results: {'mean_accepting_states': 0.898, 'accuracy': 35.699999999999996}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>mean_accepting_states</td><td>▁</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▂▁▁▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>35.7</td></tr><tr><td>mean_accepting_states</td><td>0.898</td></tr><tr><td>train_loss</td><td>0.02426</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">swept-sweep-3</strong> at: <a href='https://wandb.ai/verification_thesis/AutomatonRNN/runs/2u6em0z5' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/runs/2u6em0z5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231124_172554-2u6em0z5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5xo2gg0i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsliding_window_size: 5\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\Juan\\Ort\\Master\\IAGenerativa\\GraphRNNAutomaton\\wandb\\run-20231124_173148-5xo2gg0i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/verification_thesis/AutomatonRNN/runs/5xo2gg0i' target=\"_blank\">youthful-sweep-4</a></strong> to <a href='https://wandb.ai/verification_thesis/AutomatonRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/verification_thesis/AutomatonRNN' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/sweeps/tooxdc7e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/verification_thesis/AutomatonRNN/runs/5xo2gg0i' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/runs/5xo2gg0i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:17<00:00, 10.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!!! Final loss: 0.01994554900638293 --- Final results: {'mean_accepting_states': 0.889, 'accuracy': 38.800000000000004}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>mean_accepting_states</td><td>▁</td></tr><tr><td>train_loss</td><td>█▁▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>38.8</td></tr><tr><td>mean_accepting_states</td><td>0.889</td></tr><tr><td>train_loss</td><td>0.01995</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-sweep-4</strong> at: <a href='https://wandb.ai/verification_thesis/AutomatonRNN/runs/5xo2gg0i' target=\"_blank\">https://wandb.ai/verification_thesis/AutomatonRNN/runs/5xo2gg0i</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231124_173148-5xo2gg0i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'epochs': {'values': [30, 60]},\n",
    "    'batch_size': {'values': [32, 64, 128]},\n",
    "    'lr': {'values': [.00005, .0001, .0002]},\n",
    "    'sliding_window_size': {'values': [3, 5]},\n",
    "    'hidden_dim': {'values': [128, 256, 512, 1024]},\n",
    "    'gradient_clip': {'values': ['clip', 'norm', 'none']},\n",
    "    #'loss': {'values': ['separated', 'joined']},\n",
    "}\n",
    "\n",
    "sweep_name = get_wandb_sweep_name(automata_property, number_of_states, alphabet_len)\n",
    "sweep_id = create_sweep(sweep_name, parameters, 'random', PROJECT, ENTITY)\n",
    "\n",
    "wandb.agent(sweep_id=sweep_id, function=run_training, entity=ENTITY, project=PROJECT, count=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
