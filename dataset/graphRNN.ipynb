{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRNNAutomaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "#import wandb\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import RNN, Linear, Dropout \n",
    "from exporter import read_automatas\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "automata_property = 'minimal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'./dataset/{automata_property}_property_automatas'\n",
    "automatas = read_automatas(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_graphs(dataset, batch_size):\n",
    "    dataset1, dataset2 = dataset\n",
    "\n",
    "    batches1 = [dataset1[i:min(len(dataset1), i+batch_size)] for i in range(0, len(dataset1), batch_size)]\n",
    "    batches2 = [dataset2[i:min(len(dataset2), i+batch_size)] for i in range(0, len(dataset2), batch_size)]\n",
    "    return batches1, batches2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeMLP(nn.Module):\n",
    "    def __init__(self, m, input_dim):\n",
    "        super(EdgeMLP, self).__init__()\n",
    "        self.m = m\n",
    "\n",
    "        self.l1 = Linear(in_features=input_dim, out_features=512)\n",
    "        self.l2 = Linear(in_features=512, out_features=256)\n",
    "        self.l3 = Linear(in_features=256, out_features=512)\n",
    "        self.l4 = Linear(in_features=512, out_features=2*m+3)\n",
    "    \n",
    "        self.dropout = Dropout(p=.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = F.sigmoid(self.l1(x))\n",
    "        res = self.dropout(res)\n",
    "        res = F.leaky_relu(self.l2(res), negative_slope=.02)\n",
    "        res = self.dropout(res)\n",
    "        res = F.leaky_relu(self.l3(res), negative_slope=.02)\n",
    "        res = self.dropout(res)\n",
    "        res = F.sigmoid(self.l4(res))\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1, dropout=0):\n",
    "        super(NodeRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim \n",
    "        self.rnn = RNN(input_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        _, h = self.rnn(x, h)\n",
    "        return h[-1]\n",
    "    \n",
    "    def get_sos(self, batch_size):\n",
    "        return torch.zeros((batch_size, 1, self.input_dim))\n",
    "    \n",
    "    def get_initial_hidden(self, batch_size):\n",
    "        return torch.zeros((1, batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutomatonRNN(nn.Module):\n",
    "    def __init__(self, m, hidden_dim):\n",
    "        super(AutomatonRNN, self).__init__()\n",
    "        self.m = m\n",
    "        self.node_rnn = NodeRNN(2*m+3, hidden_dim)\n",
    "        self.edge_model = EdgeMLP(m, input_dim=hidden_dim)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        hidden = self.node_rnn(x, h)\n",
    "        return self.edge_model(hidden), hidden\n",
    "    \n",
    "    def get_sos(self, n):\n",
    "        return self.node_rnn.get_sos(n)\n",
    "\n",
    "    def get_initial_hidden(self, n):\n",
    "        return self.node_rnn.get_initial_hidden(n)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining data from a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_symbol = 0\n",
    "def add_padding_to_transitions(graphs):\n",
    "    max_len = max([len(g) for g in graphs])\n",
    "    new_graphs = []\n",
    "    for graph in graphs:\n",
    "        \n",
    "        len_diff = max_len-len(graph)\n",
    "\n",
    "        new_graph = []\n",
    "        padding = np.full(len_diff, padding_symbol)\n",
    "        for row in graph:\n",
    "            new_graph.append(np.concatenate((row, padding)))   \n",
    "\n",
    "        for _ in range(len_diff):\n",
    "            new_graph.append(np.full(max_len, padding_symbol))\n",
    "\n",
    "        new_graphs.append(new_graph)\n",
    "\n",
    "    return np.array(new_graphs)\n",
    "\n",
    "def add_padding_to_final_states(all_final_states):\n",
    "    max_len = max([len(fs) for fs in all_final_states])\n",
    "    padded_final_states = []\n",
    "    for final_states in all_final_states:\n",
    "        len_diff = max_len-len(final_states)\n",
    "        padding = np.full(len_diff, padding_symbol)\n",
    "        padded_final_states.append(np.concatenate((final_states, padding)))\n",
    "    return np.array(padded_final_states)\n",
    "\n",
    "def add_padding_to_graph(transitions, final_states):\n",
    "    return add_padding_to_transitions(transitions), add_padding_to_final_states(final_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_conns(graphs, node, m):\n",
    "    batch_size = graphs.shape[0]\n",
    "\n",
    "    initial_pos = max(0, node - m)\n",
    "    in_conns = np.array(graphs[:,initial_pos:node,node], dtype=np.float32)\n",
    "    loop_con = np.array(np.expand_dims(graphs[:,node,node],1), dtype=np.float32)\n",
    "    out_conns = np.array(graphs[:,node,initial_pos:node], dtype=np.float32)\n",
    "    \n",
    "    padding_size = max(0, m - node)\n",
    "    padding = np.zeros((batch_size,padding_size),dtype=np.float32)\n",
    "    y_conns = np.concatenate((padding, in_conns, loop_con, out_conns, padding), 1)\n",
    "    return torch.tensor(y_conns, dtype=torch.float32)\n",
    "\n",
    "def get_target_is_final(final_nodes, node):\n",
    "    return torch.tensor(final_nodes[:,node], dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "def get_target_is_end(nodes, node):\n",
    "    # we sum 0 to transform bools to int\n",
    "    return torch.tensor((nodes == node) + 0, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "def get_nodes(graphs):\n",
    "    return np.array([len(g) for g in graphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold_pred(res, m):\n",
    "    conns = res[:,:2*m+1]\n",
    "    final_prob = res[:,2*m+1]\n",
    "    end_prob = res[:,2*m+2]\n",
    "    return conns, final_prob, end_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_loss(y_hat, y):\n",
    "    conns_hat, final_prob_hat, end_prob_hat = y_hat\n",
    "    conns, final_prob, end_prob = y\n",
    "    # Convert to batch and BCE loss for conns\n",
    "    conns_loss = nn.BCELoss()(conns_hat, conns)\n",
    "    # BCE loss for final prob\n",
    "    final_prob_loss = nn.BCELoss()(final_prob_hat, final_prob)\n",
    "    # BCE loss for end prob\n",
    "    end_prob_loss = nn.BCELoss()(end_prob_hat, end_prob)\n",
    "\n",
    "    # Total loss us the sum of all losses\n",
    "    return conns_loss + final_prob_loss + end_prob_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, dataset, criterion, epochs, batch_size):\n",
    "    dataset_len = len(dataset[0])\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        loss_val = 0\n",
    "        all_transitions, all_final_states = get_batch_graphs(dataset, batch_size)\n",
    "        for i, transitions in enumerate(tqdm(all_transitions)):\n",
    "            final_states = all_final_states[i]\n",
    "            bs = len(final_states)\n",
    "\n",
    "            iter_loss = 0\n",
    "            x = model.get_sos(bs)\n",
    "            h = model.get_initial_hidden(bs)\n",
    "\n",
    "            nodes = get_nodes(transitions)\n",
    "            max_node = max(nodes)\n",
    "\n",
    "            padded_transitions, padded_final_states = add_padding_to_graph(transitions, final_states)\n",
    "            \n",
    "            for node in range(max_node):\n",
    "                optim.zero_grad()\n",
    "\n",
    "                # Get targets \n",
    "                y_conns = get_target_conns(padded_transitions, node, model.m)\n",
    "                y_final = get_target_is_final(padded_final_states, node)\n",
    "                y_end = get_target_is_end(nodes, node)\n",
    "                y = torch.cat((y_conns, y_final, y_end), 1)\n",
    "\n",
    "                # Run one iteration of the model\n",
    "                pred, hidden = model(x, h)\n",
    "                \n",
    "                # Compute the loss function\n",
    "                loss = criterion(pred, y)\n",
    "                loss.backward(retain_graph=True)\n",
    "                optim.step()\n",
    "\n",
    "                # Update hidden and x values for next iteration\n",
    "                h = hidden.reshape(1,bs,-1).detach().requires_grad_()\n",
    "                x = pred.reshape(bs,1,-1).detach().requires_grad_()\n",
    "\n",
    "                # Add the loss value\n",
    "                iter_loss += loss.item()\n",
    "\n",
    "            loss_val += iter_loss\n",
    "            #wandb.log({'train_loss':iter_loss})\n",
    "        if not epoch%0:\n",
    "            print(f\"Epoch {epoch}, duration: {time.time()-start_time}s -- TRAIN: loss {loss_val/dataset_len}\")\n",
    "                \n",
    "    return model, loss_val/dataset_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 20\n",
    "hidden_dim = 256\n",
    "automaton_rnn = AutomatonRNN(m, hidden_dim)\n",
    "criterion = nn.BCELoss(weight=torch.Tensor(np.ones(2*m+3)*100))\n",
    "\n",
    "optim = torch.optim.Adam(automaton_rnn.parameters(), lr=.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:56<00:00,  5.57it/s]\n",
      " 50%|█████     | 1/2 [00:56<00:56, 56.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, duration: 56.166069984436035s -- TRAIN: loss 13.841176894831657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:52<00:00,  5.98it/s]\n",
      "100%|██████████| 2/2 [01:48<00:00, 54.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, duration: 52.305511474609375s -- TRAIN: loss 13.63853474252224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "automaton_rnn, training_loss = train_model(automaton_rnn, optim, automatas, criterion, epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training loss 13.63853474252224\n"
     ]
    }
   ],
   "source": [
    "print(f'Final training loss {training_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}\n",
    "        self.final_nodes = set()\n",
    "        \n",
    "    def add_node(self, node, conns, is_final):\n",
    "        self.nodes[node] = set()\n",
    "        m = (len(conns)-1)//2\n",
    "        in_conns = conns[max(0, m-node):m]\n",
    "        loop_p = float(conns[m])\n",
    "        out_conns = conns[m+1:len(conns)-max(0,m-node)]\n",
    "\n",
    "        for target, p_in in enumerate(in_conns):\n",
    "            p_in = float(p_in)\n",
    "            in_connection = np.random.choice([False, True], p=[1-p_in, p_in])\n",
    "            if in_connection:\n",
    "                self.nodes[target].add(node)\n",
    "\n",
    "            p_out = float(out_conns[target])\n",
    "            out_connection = np.random.choice([False, True], p=[1-p_out, p_out])\n",
    "            if out_connection:\n",
    "                self.nodes[node].add(target)\n",
    "        \n",
    "        loop_connection = np.random.choice([False, True], p=[1-loop_p, loop_p])\n",
    "        if loop_connection:\n",
    "            self.nodes[node].add(node)\n",
    "\n",
    "        if is_final:\n",
    "            self.final_nodes.add(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REVISAR!!\n",
    "def generate(model, max_nodes, number_of_graphs):\n",
    "    with torch.no_grad():\n",
    "        graphs = [Graph() for _ in range(number_of_graphs)]\n",
    "        x = model.get_sos(number_of_graphs)\n",
    "        h = model.get_initial_hidden(number_of_graphs)\n",
    "        end = False\n",
    "        node = 0\n",
    "        while not end:\n",
    "            x, h = model(x, h)\n",
    "            conns, final_prob, end_prob = unfold_pred(x, model.m)\n",
    "            final_prob = float(final_prob)\n",
    "            is_final = np.random.choice([False, True], p=[1-final_prob, final_prob])\n",
    "            graph.add_node(node, conns, is_final)\n",
    "            end_prob = float(end_prob)\n",
    "            end = np.random.choice([False, True], p=[1-end_prob, end_prob])\n",
    "            node += 1\n",
    "            x = x.reshape(1,-1)\n",
    "            h = h.reshape(1,-1)\n",
    "\n",
    "            if node > max_nodes:\n",
    "                end = True\n",
    "\n",
    "        return graphs\n",
    "\n",
    "def generate_automatas(model, max_nodes, number_graphs):\n",
    "    return [convert_to_automata(g) for g in generate(model, max_nodes, number_graphs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Juan\\Ort\\Master\\IAGenerativa\\GraphRNNAutomaton\\graphRNN.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m graph \u001b[39m=\u001b[39m generate(automaton_rnn, \u001b[39m25\u001b[39;49m)\n",
      "\u001b[1;32me:\\Juan\\Ort\\Master\\IAGenerativa\\GraphRNNAutomaton\\graphRNN.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m final_prob \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(final_prob)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m is_final \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice([\u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m], p\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mfinal_prob, final_prob])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m graph\u001b[39m.\u001b[39;49madd_node(node, conns, is_final)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m end_prob \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(end_prob)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m end \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice([\u001b[39mFalse\u001b[39;00m, \u001b[39mTrue\u001b[39;00m], p\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mend_prob, end_prob])\n",
      "\u001b[1;32me:\\Juan\\Ort\\Master\\IAGenerativa\\GraphRNNAutomaton\\graphRNN.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m m \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(conns)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m in_conns \u001b[39m=\u001b[39m conns[\u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, m\u001b[39m-\u001b[39mnode):m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loop_p \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(conns[m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m out_conns \u001b[39m=\u001b[39m conns[m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:\u001b[39mlen\u001b[39m(conns)\u001b[39m-\u001b[39m\u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m,m\u001b[39m-\u001b[39mnode)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Juan/Ort/Master/IAGenerativa/GraphRNNAutomaton/graphRNN.ipynb#X40sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m target, p_in \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(in_conns):\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "graph = generate(automaton_rnn, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Nodes: set()\n",
      "Nodes: {0: set(), 1: set(), 2: {1, 2}, 3: set(), 4: set(), 5: set(), 6: set(), 7: {6}, 8: {3}}\n"
     ]
    }
   ],
   "source": [
    "print(f'Final Nodes: {graph.final_nodes}')\n",
    "print(f'Nodes: {graph.nodes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_automata(g, alphabet):\n",
    "    nodes = len(g.nodes.values)\n",
    "    transitions = np.fill((nodes, nodes), set())    \n",
    "    for origin, dests in g.nodes:\n",
    "        if len(dests) == 0:\n",
    "            continue\n",
    "\n",
    "        sampling_dests = dests\n",
    "        was_emptied = False\n",
    "        for symbol in alphabet:\n",
    "            dest = np.random.choice(list(sampling_dests))\n",
    "            transitions[origin, dest].add(symbol)\n",
    "            if not was_emptied:\n",
    "                sampling_dests.remove(dest)\n",
    "                \n",
    "            if len(sampling_dests) == 0:\n",
    "                sampling_dests = dests\n",
    "                was_emptied = True\n",
    "\n",
    "    return Automata(transitions, {str(n) for n in g.final_states}, alphabet, \n",
    "                initial_state='0', {str(i):i for i in range(nodes)})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from property_validator import validate_property\n",
    "def get_metrics(property, automatas):\n",
    "    return [validate_property(property, a) for a in automatas]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
